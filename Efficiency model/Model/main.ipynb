{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f98d6bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import sklearn.model_selection as sk\n",
    "\n",
    "df = pd.read_csv(\"hf://datasets/syncora/developer-productivity-simulated-behavioral-data/Developer_Productivity_Synthetic_Syncora.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db587d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hours_coding</th>\n",
       "      <th>coffee_intake_mg</th>\n",
       "      <th>distractions</th>\n",
       "      <th>sleep_hours</th>\n",
       "      <th>commits</th>\n",
       "      <th>bugs_reported</th>\n",
       "      <th>ai_usage_hours</th>\n",
       "      <th>cognitive_load</th>\n",
       "      <th>task_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.190476</td>\n",
       "      <td>575</td>\n",
       "      <td>6</td>\n",
       "      <td>7.467749</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.729743</td>\n",
       "      <td>3.666136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.069862</td>\n",
       "      <td>320</td>\n",
       "      <td>1</td>\n",
       "      <td>6.483703</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.086857</td>\n",
       "      <td>3.449533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.052262</td>\n",
       "      <td>532</td>\n",
       "      <td>3</td>\n",
       "      <td>9.687784</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514440</td>\n",
       "      <td>1.509259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.694441</td>\n",
       "      <td>359</td>\n",
       "      <td>4</td>\n",
       "      <td>8.150044</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.226923</td>\n",
       "      <td>4.099178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.883442</td>\n",
       "      <td>601</td>\n",
       "      <td>4</td>\n",
       "      <td>8.902919</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661380</td>\n",
       "      <td>3.784728</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>5.799024</td>\n",
       "      <td>532</td>\n",
       "      <td>2</td>\n",
       "      <td>4.096030</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.130257</td>\n",
       "      <td>5.657285</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>5.160282</td>\n",
       "      <td>532</td>\n",
       "      <td>5</td>\n",
       "      <td>4.978048</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.046475</td>\n",
       "      <td>9.207588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>7.435158</td>\n",
       "      <td>597</td>\n",
       "      <td>6</td>\n",
       "      <td>5.687562</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.134184</td>\n",
       "      <td>7.344275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>4.918377</td>\n",
       "      <td>402</td>\n",
       "      <td>6</td>\n",
       "      <td>6.747191</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.315910</td>\n",
       "      <td>6.314791</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>5.905045</td>\n",
       "      <td>547</td>\n",
       "      <td>5</td>\n",
       "      <td>7.271004</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.491710</td>\n",
       "      <td>4.769272</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hours_coding  coffee_intake_mg  distractions  sleep_hours  commits  \\\n",
       "0         5.190476               575             6     7.467749        6   \n",
       "1         3.069862               320             1     6.483703        0   \n",
       "2         5.052262               532             3     9.687784        9   \n",
       "3         3.694441               359             4     8.150044        3   \n",
       "4         6.883442               601             4     8.902919        5   \n",
       "...            ...               ...           ...          ...      ...   \n",
       "1995      5.799024               532             2     4.096030        4   \n",
       "1996      5.160282               532             5     4.978048        2   \n",
       "1997      7.435158               597             6     5.687562        6   \n",
       "1998      4.918377               402             6     6.747191        4   \n",
       "1999      5.905045               547             5     7.271004        5   \n",
       "\n",
       "      bugs_reported  ai_usage_hours  cognitive_load  task_success  \n",
       "0                 1        0.729743        3.666136             1  \n",
       "1                 2        0.086857        3.449533             0  \n",
       "2                 1        0.514440        1.509259             1  \n",
       "3                 0        1.226923        4.099178             0  \n",
       "4                 0        0.661380        3.784728             1  \n",
       "...             ...             ...             ...           ...  \n",
       "1995              1        3.130257        5.657285             1  \n",
       "1996              3        2.046475        9.207588             0  \n",
       "1997              1        2.134184        7.344275             0  \n",
       "1998              0        1.315910        6.314791             1  \n",
       "1999              0        1.491710        4.769272             1  \n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d138c6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:-1].to_numpy(dtype=np.float32)\n",
    "Y=df.iloc[:,-1].to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0702e032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hours_coding</th>\n",
       "      <th>coffee_intake_mg</th>\n",
       "      <th>distractions</th>\n",
       "      <th>sleep_hours</th>\n",
       "      <th>commits</th>\n",
       "      <th>bugs_reported</th>\n",
       "      <th>ai_usage_hours</th>\n",
       "      <th>cognitive_load</th>\n",
       "      <th>task_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.190476</td>\n",
       "      <td>575</td>\n",
       "      <td>6</td>\n",
       "      <td>7.467749</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.729743</td>\n",
       "      <td>3.666136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.069862</td>\n",
       "      <td>320</td>\n",
       "      <td>1</td>\n",
       "      <td>6.483703</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.086857</td>\n",
       "      <td>3.449533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.052262</td>\n",
       "      <td>532</td>\n",
       "      <td>3</td>\n",
       "      <td>9.687784</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514440</td>\n",
       "      <td>1.509259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.694441</td>\n",
       "      <td>359</td>\n",
       "      <td>4</td>\n",
       "      <td>8.150044</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.226923</td>\n",
       "      <td>4.099178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.883442</td>\n",
       "      <td>601</td>\n",
       "      <td>4</td>\n",
       "      <td>8.902919</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661380</td>\n",
       "      <td>3.784728</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>5.799024</td>\n",
       "      <td>532</td>\n",
       "      <td>2</td>\n",
       "      <td>4.096030</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.130257</td>\n",
       "      <td>5.657285</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>5.160282</td>\n",
       "      <td>532</td>\n",
       "      <td>5</td>\n",
       "      <td>4.978048</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.046475</td>\n",
       "      <td>9.207588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>7.435158</td>\n",
       "      <td>597</td>\n",
       "      <td>6</td>\n",
       "      <td>5.687562</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.134184</td>\n",
       "      <td>7.344275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>4.918377</td>\n",
       "      <td>402</td>\n",
       "      <td>6</td>\n",
       "      <td>6.747191</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.315910</td>\n",
       "      <td>6.314791</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>5.905045</td>\n",
       "      <td>547</td>\n",
       "      <td>5</td>\n",
       "      <td>7.271004</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.491710</td>\n",
       "      <td>4.769272</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hours_coding  coffee_intake_mg  distractions  sleep_hours  commits  \\\n",
       "0         5.190476               575             6     7.467749        6   \n",
       "1         3.069862               320             1     6.483703        0   \n",
       "2         5.052262               532             3     9.687784        9   \n",
       "3         3.694441               359             4     8.150044        3   \n",
       "4         6.883442               601             4     8.902919        5   \n",
       "...            ...               ...           ...          ...      ...   \n",
       "1995      5.799024               532             2     4.096030        4   \n",
       "1996      5.160282               532             5     4.978048        2   \n",
       "1997      7.435158               597             6     5.687562        6   \n",
       "1998      4.918377               402             6     6.747191        4   \n",
       "1999      5.905045               547             5     7.271004        5   \n",
       "\n",
       "      bugs_reported  ai_usage_hours  cognitive_load  task_success  \n",
       "0                 1        0.729743        3.666136             1  \n",
       "1                 2        0.086857        3.449533             0  \n",
       "2                 1        0.514440        1.509259             1  \n",
       "3                 0        1.226923        4.099178             0  \n",
       "4                 0        0.661380        3.784728             1  \n",
       "...             ...             ...             ...           ...  \n",
       "1995              1        3.130257        5.657285             1  \n",
       "1996              3        2.046475        9.207588             0  \n",
       "1997              1        2.134184        7.344275             0  \n",
       "1998              0        1.315910        6.314791             1  \n",
       "1999              0        1.491710        4.769272             1  \n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d564b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=t.from_numpy(Y)\n",
    "X=t.from_numpy(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09d6fbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 1]) torch.Size([2000, 8])\n"
     ]
    }
   ],
   "source": [
    "X.dtype\n",
    "Y=Y.reshape(-1,1)\n",
    "print(Y.size(),X.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2b43c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "X,X_test,Y,Y_test=sk.train_test_split(X,Y,test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bad9365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(8, 1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        return t.sigmoid(self.linear(x))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3467430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "criterion = nn.BCELoss() \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2bfa24a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1400, 1]) torch.Size([1400, 8])\n"
     ]
    }
   ],
   "source": [
    "print(Y.size(),X.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d00125bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000] | Loss: 0.5579 | Accuracy: 81.36%\n",
      "Epoch [200/10000] | Loss: 0.4640 | Accuracy: 85.07%\n",
      "Epoch [300/10000] | Loss: 0.4157 | Accuracy: 86.43%\n",
      "Epoch [400/10000] | Loss: 0.3860 | Accuracy: 87.43%\n",
      "Epoch [500/10000] | Loss: 0.3654 | Accuracy: 87.57%\n",
      "Epoch [600/10000] | Loss: 0.3502 | Accuracy: 87.36%\n",
      "Epoch [700/10000] | Loss: 0.3384 | Accuracy: 87.29%\n",
      "Epoch [800/10000] | Loss: 0.3288 | Accuracy: 87.36%\n",
      "Epoch [900/10000] | Loss: 0.3209 | Accuracy: 87.57%\n",
      "Epoch [1000/10000] | Loss: 0.3143 | Accuracy: 87.71%\n",
      "Epoch [1100/10000] | Loss: 0.3086 | Accuracy: 88.07%\n",
      "Epoch [1200/10000] | Loss: 0.3036 | Accuracy: 88.29%\n",
      "Epoch [1300/10000] | Loss: 0.2993 | Accuracy: 88.29%\n",
      "Epoch [1400/10000] | Loss: 0.2954 | Accuracy: 88.43%\n",
      "Epoch [1500/10000] | Loss: 0.2920 | Accuracy: 88.36%\n",
      "Epoch [1600/10000] | Loss: 0.2890 | Accuracy: 88.21%\n",
      "Epoch [1700/10000] | Loss: 0.2862 | Accuracy: 88.14%\n",
      "Epoch [1800/10000] | Loss: 0.2837 | Accuracy: 88.21%\n",
      "Epoch [1900/10000] | Loss: 0.2814 | Accuracy: 88.29%\n",
      "Epoch [2000/10000] | Loss: 0.2793 | Accuracy: 88.21%\n",
      "Epoch [2100/10000] | Loss: 0.2774 | Accuracy: 88.29%\n",
      "Epoch [2200/10000] | Loss: 0.2757 | Accuracy: 88.50%\n",
      "Epoch [2300/10000] | Loss: 0.2740 | Accuracy: 88.57%\n",
      "Epoch [2400/10000] | Loss: 0.2725 | Accuracy: 88.71%\n",
      "Epoch [2500/10000] | Loss: 0.2711 | Accuracy: 88.93%\n",
      "Epoch [2600/10000] | Loss: 0.2698 | Accuracy: 89.00%\n",
      "Epoch [2700/10000] | Loss: 0.2686 | Accuracy: 89.14%\n",
      "Epoch [2800/10000] | Loss: 0.2675 | Accuracy: 89.21%\n",
      "Epoch [2900/10000] | Loss: 0.2665 | Accuracy: 89.29%\n",
      "Epoch [3000/10000] | Loss: 0.2655 | Accuracy: 89.21%\n",
      "Epoch [3100/10000] | Loss: 0.2645 | Accuracy: 89.36%\n",
      "Epoch [3200/10000] | Loss: 0.2637 | Accuracy: 89.50%\n",
      "Epoch [3300/10000] | Loss: 0.2628 | Accuracy: 89.50%\n",
      "Epoch [3400/10000] | Loss: 0.2621 | Accuracy: 89.43%\n",
      "Epoch [3500/10000] | Loss: 0.2613 | Accuracy: 89.57%\n",
      "Epoch [3600/10000] | Loss: 0.2606 | Accuracy: 89.79%\n",
      "Epoch [3700/10000] | Loss: 0.2600 | Accuracy: 89.86%\n",
      "Epoch [3800/10000] | Loss: 0.2594 | Accuracy: 89.86%\n",
      "Epoch [3900/10000] | Loss: 0.2588 | Accuracy: 89.79%\n",
      "Epoch [4000/10000] | Loss: 0.2582 | Accuracy: 89.93%\n",
      "Epoch [4100/10000] | Loss: 0.2577 | Accuracy: 89.86%\n",
      "Epoch [4200/10000] | Loss: 0.2572 | Accuracy: 89.93%\n",
      "Epoch [4300/10000] | Loss: 0.2567 | Accuracy: 89.93%\n",
      "Epoch [4400/10000] | Loss: 0.2562 | Accuracy: 89.93%\n",
      "Epoch [4500/10000] | Loss: 0.2558 | Accuracy: 89.93%\n",
      "Epoch [4600/10000] | Loss: 0.2553 | Accuracy: 89.93%\n",
      "Epoch [4700/10000] | Loss: 0.2549 | Accuracy: 89.93%\n",
      "Epoch [4800/10000] | Loss: 0.2546 | Accuracy: 89.93%\n",
      "Epoch [4900/10000] | Loss: 0.2542 | Accuracy: 89.93%\n",
      "Epoch [5000/10000] | Loss: 0.2538 | Accuracy: 89.93%\n",
      "Epoch [5100/10000] | Loss: 0.2535 | Accuracy: 89.93%\n",
      "Epoch [5200/10000] | Loss: 0.2532 | Accuracy: 90.00%\n",
      "Epoch [5300/10000] | Loss: 0.2528 | Accuracy: 89.93%\n",
      "Epoch [5400/10000] | Loss: 0.2525 | Accuracy: 89.93%\n",
      "Epoch [5500/10000] | Loss: 0.2522 | Accuracy: 89.93%\n",
      "Epoch [5600/10000] | Loss: 0.2520 | Accuracy: 89.93%\n",
      "Epoch [5700/10000] | Loss: 0.2517 | Accuracy: 89.93%\n",
      "Epoch [5800/10000] | Loss: 0.2514 | Accuracy: 89.93%\n",
      "Epoch [5900/10000] | Loss: 0.2512 | Accuracy: 89.93%\n",
      "Epoch [6000/10000] | Loss: 0.2509 | Accuracy: 89.86%\n",
      "Epoch [6100/10000] | Loss: 0.2507 | Accuracy: 89.86%\n",
      "Epoch [6200/10000] | Loss: 0.2505 | Accuracy: 89.86%\n",
      "Epoch [6300/10000] | Loss: 0.2503 | Accuracy: 89.86%\n",
      "Epoch [6400/10000] | Loss: 0.2501 | Accuracy: 89.86%\n",
      "Epoch [6500/10000] | Loss: 0.2498 | Accuracy: 90.00%\n",
      "Epoch [6600/10000] | Loss: 0.2496 | Accuracy: 89.93%\n",
      "Epoch [6700/10000] | Loss: 0.2495 | Accuracy: 89.93%\n",
      "Epoch [6800/10000] | Loss: 0.2493 | Accuracy: 89.93%\n",
      "Epoch [6900/10000] | Loss: 0.2491 | Accuracy: 89.93%\n",
      "Epoch [7000/10000] | Loss: 0.2489 | Accuracy: 90.00%\n",
      "Epoch [7100/10000] | Loss: 0.2487 | Accuracy: 90.00%\n",
      "Epoch [7200/10000] | Loss: 0.2486 | Accuracy: 90.07%\n",
      "Epoch [7300/10000] | Loss: 0.2484 | Accuracy: 90.07%\n",
      "Epoch [7400/10000] | Loss: 0.2483 | Accuracy: 90.14%\n",
      "Epoch [7500/10000] | Loss: 0.2481 | Accuracy: 90.14%\n",
      "Epoch [7600/10000] | Loss: 0.2480 | Accuracy: 90.14%\n",
      "Epoch [7700/10000] | Loss: 0.2478 | Accuracy: 90.14%\n",
      "Epoch [7800/10000] | Loss: 0.2477 | Accuracy: 90.14%\n",
      "Epoch [7900/10000] | Loss: 0.2475 | Accuracy: 90.14%\n",
      "Epoch [8000/10000] | Loss: 0.2474 | Accuracy: 90.14%\n",
      "Epoch [8100/10000] | Loss: 0.2473 | Accuracy: 90.14%\n",
      "Epoch [8200/10000] | Loss: 0.2472 | Accuracy: 90.14%\n",
      "Epoch [8300/10000] | Loss: 0.2470 | Accuracy: 90.14%\n",
      "Epoch [8400/10000] | Loss: 0.2469 | Accuracy: 90.14%\n",
      "Epoch [8500/10000] | Loss: 0.2468 | Accuracy: 90.14%\n",
      "Epoch [8600/10000] | Loss: 0.2467 | Accuracy: 90.14%\n",
      "Epoch [8700/10000] | Loss: 0.2466 | Accuracy: 90.14%\n",
      "Epoch [8800/10000] | Loss: 0.2465 | Accuracy: 90.14%\n",
      "Epoch [8900/10000] | Loss: 0.2464 | Accuracy: 90.14%\n",
      "Epoch [9000/10000] | Loss: 0.2463 | Accuracy: 90.14%\n",
      "Epoch [9100/10000] | Loss: 0.2462 | Accuracy: 90.14%\n",
      "Epoch [9200/10000] | Loss: 0.2461 | Accuracy: 90.14%\n",
      "Epoch [9300/10000] | Loss: 0.2460 | Accuracy: 90.14%\n",
      "Epoch [9400/10000] | Loss: 0.2459 | Accuracy: 90.14%\n",
      "Epoch [9500/10000] | Loss: 0.2458 | Accuracy: 90.14%\n",
      "Epoch [9600/10000] | Loss: 0.2457 | Accuracy: 90.14%\n",
      "Epoch [9700/10000] | Loss: 0.2456 | Accuracy: 90.14%\n",
      "Epoch [9800/10000] | Loss: 0.2455 | Accuracy: 90.14%\n",
      "Epoch [9900/10000] | Loss: 0.2454 | Accuracy: 90.21%\n",
      "Epoch [10000/10000] | Loss: 0.2454 | Accuracy: 90.21%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model(X)\n",
    "    loss = criterion(y_pred, Y)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        with t.no_grad():\n",
    "            y_class = (y_pred >= 0.5).float()\n",
    "            acc = (y_class.eq(Y).sum().item() / Y.shape[0]) * 100\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Loss: {loss.item():.4f} | Accuracy: {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c0512d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.83%\n"
     ]
    }
   ],
   "source": [
    "with t.no_grad():\n",
    "    y_pred=model(X_test)\n",
    "    y_class = (y_pred >= 0.5).float()\n",
    "    acc = (y_class.eq(Y_test).sum().item() / Y_test.shape[0]) * 100\n",
    "    print(f\"Accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b63fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
